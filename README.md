# OpenShift on OpenShift Virtualization

> **_NOTE:_** All content below together with the scripts and manifests were generated by AI. 

This repository provides automated tooling and configurations for deploying OpenShift clusters on top of OpenShift Virtualization. It supports both Single Node OpenShift (SNO) and Multi Node OpenShift (MNO) deployments using Agent Based Installer (ABI) with virtual machines.

## Overview

The solution leverages OpenShift Virtualization to create virtual machines that host OpenShift clusters, providing a nested virtualization approach for OpenShift deployments. This is particularly useful for testing, development, and edge computing scenarios.

## Repository Structure

```
openshift-on-openshift-virtualization/
├── README.md                           # This file
├── pre-setup.sh                        # Sets up local network configuration
├── install-sno.sh                      # SNO installation script  
├── install-mno.sh                      # MNO installation script
├── abi-configs/                        # Agent Based Installer configurations
│   ├── sno100.yaml                     # SNO cluster configuration
│   ├── vacm1.yaml                      # MNO cluster configuration (vacm1)
│   └── vacm2.yaml                      # MNO cluster configuration (vacm2)
└── virtual-machines/                   # VM definitions and networking
    ├── localnet.yaml                   # Local network bridge mapping
    ├── vsno/                           # SNO VM configurations
    │   └── sno100/                     # SNO100 cluster VMs
    ├── vacm1/                          # VACM1 cluster VMs
    │   ├── kustomization.yaml          # Kustomize configuration
    │   ├── ns.yaml                     # Namespace definition
    │   ├── network-attachment-definition.yaml
    │   ├── vm-master1.yaml             # Master node 1 VM
    │   ├── vm-master2.yaml             # Master node 2 VM
    │   └── vm-master3.yaml             # Master node 3 VM
    └── vacm2/                          # VACM2 cluster VMs
        └── [similar structure to vacm1]
```

## Prerequisites

### Infrastructure Requirements
- OpenShift cluster with OpenShift Virtualization operator installed
- Sufficient compute resources for nested virtualization
- Network connectivity for VM management
- Storage for VM disks and ISO images

### Software Dependencies
- `oc` (OpenShift CLI)
- `virtctl` (KubeVirt CLI)
- `git` for cloning dependencies
- Web server for hosting ISO images (configured at `http://192.168.58.15/iso/`)

### External Dependencies
This repository depends on external tools:
- [sno-agent-based-installer](https://github.com/borball/sno-agent-based-installer) - For SNO deployments
- [mno-with-abi](https://github.com/borball/mno-with-abi) - For MNO deployments

## Configuration

### ABI Configuration Files

The `abi-configs/` directory contains cluster-specific configurations:

#### SNO Configuration (`sno100.yaml`)
```yaml
cluster:
  domain: outbound.vz.bos2.lab
  name: sno100

host:
  interface: ens1f0
  hostname: sno100.outbound.vz.bos2.lab
  mac: de:ad:be:ff:80:00
  ipv4:
    enabled: true
    dhcp: false
    ip: 192.168.58.100
    dns:
      - 192.168.58.15
    gateway: 192.168.58.1
    prefix: 25
    machine_network_cidr: 192.168.58.0/25
  disk: /dev/vda

cpu:
  isolated: 4-23
  reserved: 0-3

proxy:
  enabled: false

ssh_key: ${HOME}/.ssh/id_rsa.pub
pull_secret: ${HOME}/pull-secret.json


iso:
  address: http://192.168.58.15/iso/sno100.iso
```

#### MNO Configuration (`vacm1.yaml` example)
```yaml
cluster:
  domain: outbound.vz.bos2.lab
  name: vacm1
  apiVIPs: ["192.168.58.50"]
  ingressVIPs: ["192.168.58.54"]

hosts:
  common:
    ipv4:
      enabled: true
      dhcp: false
      machine_network_cidr: 192.168.58.0/25
      dns: 192.168.58.15
      gateway: 192.168.58.1
    disk: /dev/vda

  masters:
    - hostname: master1.vacm1.outbound.vz.bos2.lab
      interface: ens1f0
      mac: de:ad:be:ff:20:00
      ipv4:
        ip: 192.168.58.51
    # ... additional masters
```

### Virtual Machine Specifications

#### SNO VM Configuration
- **CPU**: 8 cores, 1 socket, 2 threads
- **CPU Isolation**: Cores 4-23 isolated, 0-3 reserved (configurable)
- **Memory**: 24Gi
- **Storage**: 120Gi root disk + 100Gi data disk
- **Network**: Virtio interface with localnet networking
- **MAC Address**: de:ad:be:ff:80:00

#### MNO VM Configuration (per node)
- **CPU**: 8 cores, 1 socket, 2 threads  
- **Memory**: 16Gi
- **Storage**: 120Gi root disk + 100Gi data disk
- **Network**: Virtio interface with localnet networking

## Usage

### 1. Pre-setup
Set up the local network configuration:
```bash
./pre-setup.sh
```

This creates the necessary network bridge mappings for VM connectivity.

### 2. Deploy Single Node OpenShift (SNO)
```bash
./install-sno.sh <cluster-name>
```

Example:
```bash
./install-sno.sh sno100
```

This script:
1. Clones the `sno-agent-based-installer` repository
2. Copies the ABI configuration file
3. Generates the OpenShift ISO using `sno-iso.sh`
4. Copies the ISO to the web server location
5. Creates the VM using Kustomize
6. Powers on the VM using `virtctl`

**Note**: The current script includes TODO items for future enhancements:
- Monitor the installation progress
- Change VM boot order to boot from disk after installation
- Wait for cluster to be ready
- Unmount the ISO from the VM

### 3. Deploy Multi Node OpenShift (MNO)
```bash
./install-mno.sh <cluster-name>
```

Example:
```bash
./install-mno.sh vacm1
```

This script provides a complete automated deployment workflow:
1. Clones the `mno-with-abi` repository
2. Copies the ABI configuration file
3. Generates the OpenShift ISO using `mno-iso.sh`
4. Copies the ISO to the web server location
5. Creates all master VMs using Kustomize
6. Waits for all DataVolumes to be ready (up to 10 minutes)
7. Powers on all master VMs using `virtctl`
8. Monitors the installation progress via the Assisted Service API
9. Waits for cluster stability (5-minute minimum stable period)
10. Provides detailed progress reporting throughout the process

**Features**:
- **Automated monitoring**: Tracks installation progress and completion
- **DataVolume readiness**: Ensures VMs are ready before powering on
- **Cluster stability**: Waits for cluster to reach stable state
- **Progress reporting**: Shows installation percentage and status
- **Error handling**: Includes timeout and retry mechanisms

## Network Configuration

### Local Network Bridge Mapping
The `localnet.yaml` file configures OVN bridge mappings:
- Maps `localnet-network` to the `br-ex` bridge
- Applied to worker nodes for VM networking

### Network Attachment Definition
Each cluster uses a `NetworkAttachmentDefinition` for VM networking:
- **Type**: `ovn-k8s-cni-overlay`
- **Topology**: `localnet`
- **CNI Version**: 0.3.1

## VM Management

### Starting VMs
```bash
# SNO
virtctl start <cluster-name> -n <cluster-name>

# MNO
virtctl start master1 -n <cluster-name>
virtctl start master2 -n <cluster-name>
virtctl start master3 -n <cluster-name>
```

### Stopping VMs
```bash
virtctl stop <vm-name> -n <namespace>
```

### Accessing VMs
```bash
virtctl console <vm-name> -n <namespace>
```

## Customization

### Adding New Clusters
1. Create ABI configuration file in `abi-configs/`
2. Create VM definitions in `virtual-machines/`
3. Update MAC addresses and IP configurations
4. Ensure unique cluster names and namespaces

### Modifying VM Resources
Edit the VM YAML files to adjust:
- CPU cores and memory
- Storage sizes
- Network interfaces
- Boot order and devices

### Network Customization
Modify network configurations in:
- `localnet.yaml` for bridge mappings
- `network-attachment-definition.yaml` for VM networking
- ABI configs for cluster networking

## Troubleshooting

### Common Issues
1. **ISO not found**: Ensure the web server is running and ISO files are accessible
2. **VM creation fails**: Check resource availability and storage classes
3. **Network connectivity**: Verify bridge mappings and NetworkAttachmentDefinitions
4. **Boot issues**: Check VM console logs and boot order configuration
5. **DataVolume timeout**: If DataVolumes don't become ready within 10 minutes, check storage provisioning
6. **Installation monitoring fails**: Verify SSH access to the rendezvous node and assisted service availability
7. **Cluster stability timeout**: The MNO script waits for 5-minute stability; check cluster health during this phase

### Debugging Commands
```bash
# Check VM status
oc get vms -n <namespace>

# Check VM details
oc describe vm <vm-name> -n <namespace>

# Check DataVolume status
oc get dv -n <namespace>

# Check network configuration
oc get network-attachment-definitions -n <namespace>

# Access VM console
virtctl console <vm-name> -n <namespace>

# Monitor cluster installation status (for MNO)
oc adm wait-for-stable-cluster --minimum-stable-period=5m

# Check assisted service logs (on rendezvous node)
ssh core@<rendezvous-ip> journalctl -u assisted-service
```

## Dependencies and Requirements

### OpenShift Cluster Requirements
- OpenShift Virtualization operator installed
- Sufficient worker nodes with virtualization capabilities
- CNV (Container Native Virtualization) configured
- Storage classes for VM disks

### Network Requirements
- Bridge network configuration on worker nodes
- Access to ISO hosting web server
- Proper DNS resolution for cluster domains

### Resource Planning
- **SNO**: ~24Gi RAM, 8 vCPUs, 220Gi storage per cluster
- **MNO**: ~48Gi RAM, 24 vCPUs, 660Gi storage per cluster (3 masters)

## Execution Example

### MNO

```
# ./install-mno.sh vacm2
Will use /root/github/openshift-on-openshift-virtualization/mno-with-abi/instances/vacm2/config-resolved.yaml as the configuration in other mno-* scripts.
Container runtime crun(4.18+):                         default
Red Hat Advanced Cluster Management for Kubernetes     enabled
Topology Aware Lifecycle Manager                       enabled
OpenShift Data Foundation                              enabled
Copy customized CRs from extra-manifests folder if present

Generating boot image...

INFO Configuration has 3 master replicas and 0 worker replicas
INFO The rendezvous host IP (node0 IP) is 192.168.58.71
INFO Extracting base ISO from release payload
INFO Verifying cached file
INFO Using cached Base ISO /root/.cache/agent/image_cache/coreos-x86_64.iso
INFO Consuming Agent Config from target directory
INFO Consuming Install Config from target directory
INFO Consuming Extra Manifests from target directory
INFO Generated ISO at /root/github/openshift-on-openshift-virtualization/mno-with-abi/instances/vacm2/agent.x86_64.iso.

------------------------------------------------
kubeconfig: /root/github/openshift-on-openshift-virtualization/mno-with-abi/instances/vacm2/auth/kubeconfig.
kubeadmin password: /root/github/openshift-on-openshift-virtualization/mno-with-abi/instances/vacm2/auth/kubeadmin-password.
------------------------------------------------

Next step: Go to your BMC console and boot the node from ISO: /root/github/openshift-on-openshift-virtualization/mno-with-abi/instances/vacm2/agent.x86_64.iso.
You can also run ./mno-install.sh to boot the node from the image automatically if you have a HTTP server serves the image.
Enjoy!
ISO created and copied to /var/www/html/iso/vacm2.iso, which is served by the web server http://192.168.58.15/iso

Creating the VMs...
namespace/vacm2 unchanged
networkattachmentdefinition.k8s.cni.cncf.io/localnet-network unchanged
virtualmachine.kubevirt.io/master1 created
virtualmachine.kubevirt.io/master2 created
virtualmachine.kubevirt.io/master3 created

Waiting for all the VMs being ready...
datavolume.cdi.kubevirt.io/master1-cdrom phase null is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master1-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master1-data phase ImportScheduled is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master1-data DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master1-rootdisk phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master1-rootdisk DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master2-cdrom phase ImportScheduled is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master2-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master3-cdrom phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master3-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master1-cdrom phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master1-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master2-cdrom phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master2-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master2-cdrom phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master2-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master2-cdrom phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master2-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master2-cdrom phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master2-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/master2-cdrom phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/master2-cdrom DataVolume to be and succeed...
All the VMs are ready to power on.
Powering on the VMs to start the installation.
VM master1 was scheduled to start
VM master2 was scheduled to start
VM master3 was scheduled to start

Monitoring the installation...
Fetching the API token...
API token: eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdXRoX3NjaGVtZSI6InVzZXJBdXRoIn0.9yJ-OWjWZRixvR2dMZtqGlvGTdGyPn2MbKhxi-bgABxCZjSXUw9b1OZC4aXUFwz5AsuuTnVoRxjqix5YZXebEA

Fetching the Assisted REST URL...
Assisted REST URL: http://192.168.58.71:8090/api/assisted-install/v2/clusters

.......
Installing in progress...
-------------------------------
{"enabled_host_count":3,"name":"vacm2","status":"insufficient","status_info":"Cluster is not ready for install","status_updated_at":"2025-07-11T19:45:34.464Z","total_host_count":3,"updated_at":"2025-07-11T19:45:42.810576Z","user_name":"admin","validations_info":{"configuration":[{"status":"success","message":"Platform requirements satisfied"},{"status":"success","message":"The pull secret is set."}],"hosts-data":[{"status":"failure","message":"The cluster has hosts that are not ready to install."},{"status":"success","message":"The cluster has the exact amount of dedicated control plane nodes."}],"network":[{"status":"success","message":"API virtual IPs are defined."},{"status":"failure","message":"api vips <192.168.58.70> are not verified yet."},{"status":"success","message":"The Cluster Network CIDR is defined."},{"status":"success","message":"The base domain is defined."},{"status":"success","message":"Ingress virtual IPs are defined."},{"status":"failure","message":"ingress vips <192.168.58.74> are not verified yet."},{"status":"success","message":"The Machine Network CIDR is defined."},{"status":"success","message":"The Cluster Machine CIDR is equivalent to the calculated CIDR."},{"status":"success","message":"The Cluster Network prefix is valid."},{"status":"success","message":"The cluster has a valid network type"},{"status":"success","message":"Same address families for all networks."},{"status":"success","message":"No CIDRS are overlapping."},{"status":"success","message":"No ntp problems found"},{"status":"success","message":"The Service Network CIDR is defined."}],"operators":[{"status":"success","message":"cnv is disabled"},{"status":"success","message":"lso is disabled"},{"status":"success","message":"lvm is disabled"},{"status":"success","message":"mce is disabled"},{"status":"success","message":"mtv is disabled"},{"status":"success","message":"node-feature-discovery is disabled"},{"status":"success","message":"nvidia-gpu is disabled"},{"status":"success","message":"odf is disabled"},{"status":"success","message":"openshift-ai is disabled"},{"status":"success","message":"pipelines is disabled"},{"status":"success","message":"serverless is disabled"},{"status":"success","message":"servicemesh is disabled"}]}}
-------------------------------

Installation in progress: completed 10/100
Installation in progress: completed 35/100........
Installation in progress: completed 45/100....
Installation in progress: completed 50/100.......
Installation in progress: completed 59/100
Installation in progress: completed 65/100..................
Installation in progress: completed 68/100
-------------------------------
Nodes Rebooted...
19 minutes and 21 seconds elapsed.
Waiting for the cluster to be stable...
Waiting for the cluster to be stable...
clusteroperators/authentication is unavailable and degraded at 2025-07-11T20:02:21Z
......................................................................................
clusteroperators/authentication is still unavailable and degraded after 1m10s
.............................................................................
clusteroperators/authentication is still unavailable and progressing and degraded after 2m20s
.............................................................................................
clusteroperators/authentication is still unavailable and progressing after 4m40s
...........................................................................
..
......
All clusteroperators are still stable after 4m30s
.....
All clusteroperators are stable
Virtualization cluster info:
--------------------------------
NAME                                 STATUS   ROLES                         AGE   VERSION
master1.vacm2.outbound.vz.bos2.lab   Ready    control-plane,master,worker   18m   v1.31.9
master2.vacm2.outbound.vz.bos2.lab   Ready    control-plane,master,worker   31m   v1.31.9
master3.vacm2.outbound.vz.bos2.lab   Ready    control-plane,master,worker   31m   v1.31.9
--------------------------------
NAME      VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS
version   4.18.19   True        False         11m     Cluster version is 4.18.19
--------------------------------
NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
authentication                             4.18.19   True        False         False      12m
baremetal                                  4.18.19   True        False         False      27m
cloud-controller-manager                   4.18.19   True        False         False      31m
cloud-credential                           4.18.19   True        False         False      32m
cluster-autoscaler                         4.18.19   True        False         False      27m
config-operator                            4.18.19   True        False         False      28m
console                                    4.18.19   True        False         False      17m
control-plane-machine-set                  4.18.19   True        False         False      27m
csi-snapshot-controller                    4.18.19   True        False         False      28m
dns                                        4.18.19   True        False         False      27m
etcd                                       4.18.19   True        False         False      26m
image-registry                             4.18.19   True        False         False      17m
ingress                                    4.18.19   True        False         False      21m
insights                                   4.18.19   True        False         False      27m
kube-apiserver                             4.18.19   True        False         False      24m
kube-controller-manager                    4.18.19   True        False         False      25m
kube-scheduler                             4.18.19   True        False         False      24m
kube-storage-version-migrator              4.18.19   True        False         False      28m
machine-api                                4.18.19   True        False         False      24m
machine-approver                           4.18.19   True        False         False      28m
machine-config                             4.18.19   True        False         False      27m
marketplace                                4.18.19   True        False         False      27m
monitoring                                 4.18.19   True        False         False      15m
network                                    4.18.19   True        False         False      28m
node-tuning                                4.18.19   True        False         False      18m
olm                                        4.18.19   True        False         False      15m
openshift-apiserver                        4.18.19   True        False         False      19m
openshift-controller-manager               4.18.19   True        False         False      24m
openshift-samples                          4.18.19   True        False         False      19m
operator-lifecycle-manager                 4.18.19   True        False         False      27m
operator-lifecycle-manager-catalog         4.18.19   True        False         False      27m
operator-lifecycle-manager-packageserver   4.18.19   True        False         False      19m
service-ca                                 4.18.19   True        False         False      28m
storage                                    4.18.19   True        False         False      28m
--------------------------------
NAME                                       DISPLAY                                      VERSION
advanced-cluster-management.v2.13.3        Advanced Cluster Management for Kubernetes   2.13.3
cephcsi-operator.v4.18.6-rhodf             CephCSI operator                             4.18.6-rhodf
mcg-operator.v4.18.6-rhodf                 NooBaa Operator                              4.18.6-rhodf
ocs-client-operator.v4.18.6-rhodf          OpenShift Data Foundation Client             4.18.6-rhodf
ocs-operator.v4.18.6-rhodf                 OpenShift Container Storage                  4.18.6-rhodf
odf-csi-addons-operator.v4.18.6-rhodf      CSI Addons                                   4.18.6-rhodf
odf-dependencies.v4.18.6-rhodf             Data Foundation Dependencies                 4.18.6-rhodf
odf-operator.v4.18.6-rhodf                 OpenShift Data Foundation                    4.18.6-rhodf
odf-prometheus-operator.v4.18.6-rhodf      Prometheus Operator                          4.18.6-rhodf
packageserver                              Package Server                               0.0.1-snapshot
recipe.v4.18.6-rhodf                       Recipe                                       4.18.6-rhodf
rook-ceph-operator.v4.18.6-rhodf           Rook-Ceph                                    4.18.6-rhodf
topology-aware-lifecycle-manager.v4.18.0   Topology Aware Lifecycle Manager             4.18.0
```


### SNO

```
# ./install-sno.sh sno100
Creating workspace: /root/github/openshift-on-openshift-virtualization/sno-agent-based-installer/instances/sno100.
Will use /root/github/openshift-on-openshift-virtualization/sno-agent-based-installer/instances/sno100/config-resolved.yaml as the configuration in other sno-* scripts.
You are going to download OpenShift installer stable-4.18: 4.18.19

Enabling day1 configuration...
Workload partitioning:                                   enabled(through install-config)
SNO boot accelerate:                                     enabled
kdump, blacklist_ice(for HPE):                           disabled
Container runtime crun(4.18+):                           default
SR-IOV kernel(intel iommu):                              enabled
- 07-sriov-related-kernel-args-master.intel.yaml         added
Set rcu_normal=1 after node reboot:                      enabled
Sync time once after node reboot:                        enabled
default cgv2, enable cgroup v1:                          false
Container storage partition:                             disabled

Enabling operators...
PTP Operator                                             enabled
Local Storage Operator                                   enabled
Red Hat Advanced Cluster Management for Kubernetes       disabled
Red Hat OpenShift GitOps                                 disabled
Topology Aware Lifecycle Manager                         disabled
SR-IOV Network Operator for Openshift                    enabled
Logical Volume Manager Storage Operator                  disabled
Multicluster Engine for Kubernetes                       disabled
Multicluster Global Hub Operator                         disabled
OpenShift Logging Operator                               disabled
Intel SRIOV-FEC Operator                                 disabled
OpenShift API for Data Protection Operator               disabled
OpenShift Lifecycle Agent Operator                       disabled
MetalLB Operator                                         disabled
NMState Operator                                         disabled
OpenShift Virtualization                                 disabled
Node Feature Discovery Operator                          disabled
NVIDIA GPU Operator                                      disabled

Configuring operators...


Generating boot image...

INFO Configuration has 1 master replicas and 0 worker replicas
INFO The rendezvous host IP (node0 IP) is 192.168.58.100
INFO Extracting base ISO from release payload
INFO Verifying cached file
INFO Using cached Base ISO /root/.cache/agent/image_cache/coreos-x86_64.iso
INFO Consuming Extra Manifests from target directory
INFO Consuming Install Config from target directory
INFO Consuming Agent Config from target directory
INFO Generated ISO at /root/github/openshift-on-openshift-virtualization/sno-agent-based-installer/instances/sno100/agent.x86_64.iso.

------------------------------------------------
kubeconfig: /root/github/openshift-on-openshift-virtualization/sno-agent-based-installer/instances/sno100/auth/kubeconfig.
kubeadmin password: /root/github/openshift-on-openshift-virtualization/sno-agent-based-installer/instances/sno100/auth/kubeadmin-password.
------------------------------------------------

Next step: Go to your BMC console and boot the node from ISO: /root/github/openshift-on-openshift-virtualization/sno-agent-based-installer/instances/sno100/agent.x86_64.iso.
You can also run ./sno-install.sh to boot the node from the image automatically if you have a HTTP server serves the image.
Enjoy!
ISO created and copied to /var/www/html/iso/sno100.iso, which is served by the web server http://192.168.58.15/iso

Creating the VM...
namespace/sno100 unchanged
networkattachmentdefinition.k8s.cni.cncf.io/localnet-network unchanged
virtualmachine.kubevirt.io/sno100 created

Waiting for the VM being ready to power on...
Waiting for the VM's DataVolume to be created...
datavolume.cdi.kubevirt.io/sno100-cdrom phase ImportScheduled is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/sno100-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/sno100-data phase null is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/sno100-data DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/sno100-rootdisk phase ImportScheduled is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/sno100-rootdisk DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/sno100-cdrom phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/sno100-cdrom DataVolume to be and succeed...
datavolume.cdi.kubevirt.io/sno100-cdrom phase ImportInProgress is not Succeeded yet; Waiting for the datavolume.cdi.kubevirt.io/sno100-cdrom DataVolume to be and succeed...
The VM is ready to power on.

Powering on the VM to start the installation.
VM sno100 was scheduled to start

Monitoring the installation...
Fetching the API token...
API token: eyJhbGciOiJFUzI1NiIsInR5cCI6IkpXVCJ9.eyJhdXRoX3NjaGVtZSI6InVzZXJBdXRoIn0.akDrPTcC7gfJ422uArBI5NWpbeztNgByjTy_uznkSf5LJcZVRPedIzwv1o4d8HlLB7UqWCAiaK-oQCdDOZiY1A

Fetching the Assisted REST URL...
Assisted REST URL: http://api.sno100.outbound.vz.bos2.lab:8090/api/assisted-install/v2/clusters

......
Installing in progress...
-------------------------------
{"enabled_host_count":1,"name":"sno100","status":"insufficient","status_info":"Cluster is not ready for install","status_updated_at":"2025-07-11T22:05:12.273Z","total_host_count":1,"updated_at":"2025-07-11T22:05:12.566566Z","user_name":"admin"}
-------------------------------
{"enabled_host_count":1,"name":"sno100","status":"insufficient","status_info":"Cluster is not ready for install","status_updated_at":"2025-07-11T22:05:12.273Z","total_host_count":1,"updated_at":"2025-07-11T22:05:17.882968Z","user_name":"admin","validations_info":{"configuration":[{"status":"success","message":"Platform requirements satisfied"},{"status":"success","message":"The pull secret is set."}],"hosts-data":[{"status":"failure","message":"The cluster has hosts that are not ready to install."},{"status":"success","message":"The cluster has the exact amount of dedicated control plane nodes."}],"network":[{"status":"success","message":"API virtual IPs are not required: User Managed Networking"},{"status":"success","message":"API virtual IPs are not required: User Managed Networking"},{"status":"success","message":"The Cluster Network CIDR is defined."},{"status":"success","message":"The base domain is defined."},{"status":"success","message":"Ingress virtual IPs are not required: User Managed Networking"},{"status":"success","message":"Ingress virtual IPs are not required: User Managed Networking"},{"status":"success","message":"The Machine Network CIDR is defined."},{"status":"success","message":"The Cluster Machine CIDR is not required: User Managed Networking"},{"status":"success","message":"The Cluster Network prefix is valid."},{"status":"success","message":"The cluster has a valid network type"},{"status":"success","message":"Same address families for all networks."},{"status":"success","message":"No CIDRS are overlapping."},{"status":"success","message":"No ntp problems found"},{"status":"success","message":"The Service Network CIDR is defined."}],"operators":[{"status":"success","message":"cnv is disabled"},{"status":"success","message":"lso is disabled"},{"status":"success","message":"lvm is disabled"},{"status":"success","message":"mce is disabled"},{"status":"success","message":"mtv is disabled"},{"status":"success","message":"node-feature-discovery is disabled"},{"status":"success","message":"nvidia-gpu is disabled"},{"status":"success","message":"odf is disabled"},{"status":"success","message":"openshift-ai is disabled"},{"status":"success","message":"pipelines is disabled"},{"status":"success","message":"serverless is disabled"},{"status":"success","message":"servicemesh is disabled"}]}}

Installation in progress: completed 10/100
Installation in progress: completed 39/100........
Installation in progress: completed 49/100....
-------------------------------
Node Rebooted...
Waiting for the cluster to be stable...
failed to list clusteroperators: Get "https://api.sno100.outbound.vz.bos2.lab:6443/apis/config.openshift.io/v1/clusteroperators": dial tcp 192.168.58.100:6443: connect: connection refused
............................................
clusteroperators/authentication is still unavailable and progressing and degraded after 20s
...........................................................................................................................................
clusteroperators/authentication is still unavailable and progressing and degraded after 1m30s
..........................................................................................................................................
clusteroperators/authentication is still unavailable and degraded after 14m50s
....
clusteroperators/monitoring is still unavailable and progressing and degraded after 26m20s
.......
clusteroperators/kube-controller-manager is still progressing after 20s
.......
All clusteroperators are still stable after 30s
....
All clusteroperators are stable
Virtualization cluster info:
--------------------------------
NAME                          STATUS   ROLES                         AGE   VERSION
sno100.outbound.vz.bos2.lab   Ready    control-plane,master,worker   28m   v1.31.9
--------------------------------
NAME      VERSION   AVAILABLE   PROGRESSING   SINCE   STATUS
version   4.18.19   True        False         107s    Cluster version is 4.18.19
--------------------------------
NAME                                       VERSION   AVAILABLE   PROGRESSING   DEGRADED   SINCE   MESSAGE
authentication                             4.18.19   True        False         False      3m21s
config-operator                            4.18.19   True        False         False      26m
dns                                        4.18.19   True        False         False      7m18s
etcd                                       4.18.19   True        False         False      14m
ingress                                    4.18.19   True        False         False      26m
kube-apiserver                             4.18.19   True        False         False      7m25s
kube-controller-manager                    4.18.19   True        False         False      13m
kube-scheduler                             4.18.19   True        False         False      13m
kube-storage-version-migrator              4.18.19   True        False         False      26m
machine-approver                           4.18.19   True        False         False      26m
machine-config                             4.18.19   True        False         False      26m
monitoring                                 4.18.19   True        False         False      2m5s
network                                    4.18.19   True        False         False      26m
node-tuning                                4.18.19   True        False         False      26m
openshift-apiserver                        4.18.19   True        False         False      7m24s
openshift-controller-manager               4.18.19   True        False         False      15m
operator-lifecycle-manager                 4.18.19   True        False         False      20m
operator-lifecycle-manager-catalog         4.18.19   True        False         False      20m
operator-lifecycle-manager-packageserver   4.18.19   True        False         False      7m33s
service-ca                                 4.18.19   True        False         False      26m
--------------------------------
NAME                                          DISPLAY                   VERSION
local-storage-operator.v4.18.0-202506241202   Local Storage             4.18.0-202506241202
packageserver                                 Package Server            0.0.1-snapshot
ptp-operator.v4.18.0-202506260833             PTP Operator              4.18.0-202506260833
sriov-network-operator.v4.18.0-202506230505   SR-IOV Network Operator   4.18.0-202506230505

```